// scripts/build-embeddings.mjs
import fs from "fs";
import path from "path";
import pdf from "pdf-parse";
import OpenAI from "openai";

const DOCS_DIR = "docs";
const DATA_DIR = "data";
const MODEL = process.env.EMB_MODEL || "text-embedding-3-small";
const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

if (!fs.existsSync(DOCS_DIR)) {
  console.error("No existe /docs con los PDFs.");
  process.exit(1);
}
if (!fs.existsSync(DATA_DIR)) fs.mkdirSync(DATA_DIR);

const chunksPath = path.join(DATA_DIR, "chunks.jsonl");
const embsPath   = path.join(DATA_DIR, "embeddings.jsonl");
fs.writeFileSync(chunksPath, "");
fs.writeFileSync(embsPath,   "");

function chunk(text, size = 1200, overlap = 200) {
  const out = [];
  let i = 0, n = text.length;
  while (i < n) {
    let j = Math.min(n, i + size), cut = j;
    for (const sep of [". ", "\n", " "]) {
      const k = text.lastIndexOf(sep, j);
      if (k > i + 200) { cut = k + sep.length; break; }
    }
    const piece = text.slice(i, cut).trim();
    if (piece) out.push(piece);
    i = Math.max(cut - overlap, cut);
  }
  return out;
}

async function extractText(filePath) {
  try {
    const data = await pdf(fs.readFileSync(filePath));
    return (data.text || "").trim();
  } catch {
    return "";
  }
}

const pdfs = fs.readdirSync(DOCS_DIR)
  .filter(f => f.toLowerCase().endsWith(".pdf"))
  .sort();

const allChunks = [];
console.log(`Encontrados ${pdfs.length} PDFs. Extrayendo texto y generando chunks…`);
for (const name of pdfs) {
  const fp = path.join(DOCS_DIR, name);
  const text = await extractText(fp);
  const parts = chunk(text || name); // fallback: usa el nombre si no pudo extraer
  parts.forEach((t, idx) => {
    const rec = { doc: name, chunk: idx, text: t, path: `docs/${name}` };
    allChunks.push(rec);
    fs.appendFileSync(chunksPath, JSON.stringify(rec) + "\n");
  });
}
console.log(`Chunks generados: ${allChunks.length}. Creando embeddings con ${MODEL}…`);

const BATCH = 64;
for (let i = 0; i < allChunks.length; i += BATCH) {
  const batch = allChunks.slice(i, i + BATCH);
  const resp = await client.embeddings.create({
    model: MODEL,
    input: batch.map(r => r.text)
  });
  resp.data.forEach((e, k) => {
    const r = batch[k];
    fs.appendFileSync(embsPath, JSON.stringify({
      doc: r.doc, chunk: r.chunk, path: r.path, embedding: e.embedding
    }) + "\n");
  });
  console.log(`Embeddings ${Math.min(i + BATCH, allChunks.length)}/${allChunks.length}`);
}

console.log("Listo:", chunksPath, embsPath);